bash -lc '
set -euo pipefail

# ========= Tham s·ªë ‚Äúc√≥ th·ªÉ‚Äù ch·ªânh =========
REGION="${REGION:-asia-southeast1}"
SERVICE="${SERVICE:-invoice-fe}"
REPO="${REPO:-invoice-pipeline}"
APP_DIR="$HOME/invoice-pipeline/fe"
ROOT_DIR="$HOME/invoice-pipeline"
# ==========================================

PROJECT_ID="$(gcloud config get-value project 2>/dev/null)"
if [ -z "$PROJECT_ID" ] || [ "$PROJECT_ID" = "(unset)" ]; then
  echo "‚ùå Ch∆∞a c√≥ PROJECT_ID trong gcloud config"; exit 1
fi

mkdir -p "$APP_DIR/.streamlit"

# ===== 1) Ghi ƒë√® FE/streamlit_app.py (b·∫£n m·ªõi) =====
if [ -f "$APP_DIR/streamlit_app.py" ]; then
  cp "$APP_DIR/streamlit_app.py" "$APP_DIR/streamlit_app.py.bak.$(date +%Y%m%d-%H%M%S)"
fi

cat > "$APP_DIR/streamlit_app.py" <<'\PY'
from __future__ import annotations
import io, os, time
from pathlib import Path
from typing import Dict, Any, List, Tuple

import requests
import streamlit as st

st.set_page_config(page_title="Invoice Pipeline ‚Äì Upload & Convert", layout="wide")
TTL_SECONDS = 5 * 60
AUTO_REFRESH_MS = 30_000

SECRETS_DIR  = (Path(__file__).parent / ".streamlit")
SECRETS_FILE = SECRETS_DIR / "secrets.toml"

def _read_toml_text(p: Path) -> Dict[str, Any]:
    try:
        if not p.exists():
            return {}
        try:
            import tomllib
            return tomllib.loads(p.read_text(encoding="utf-8"))
        except Exception:
            import tomli
            return tomli.loads(p.read_text(encoding="utf-8"))
    except Exception:
        return {}

def _write_backend_url(url: str) -> None:
    SECRETS_DIR.mkdir(parents=True, exist_ok=True)
    SECRETS_FILE.write_text(f\'backend_url = "{url.strip()}"\n\', encoding="utf-8")

def _resolve_backend_url() -> str:
    env = os.environ.get("BACKEND_URL", "").strip()
    if env:
        return env
    toml = _read_toml_text(SECRETS_FILE)
    if "backend_url" in toml and str(toml["backend_url"]).strip():
        return str(toml["backend_url"]).strip()
    return ""

def _join(base: str, path: str) -> str:
    return base.rstrip("/") + (path if path.startswith("/") else f"/{path}")

def _init_state():
    if "uploads" not in st.session_state:
        st.session_state["uploads"] = {}
    if "last_activity" not in st.session_state:
        st.session_state["last_activity"] = time.time()

def _cleanup_ttl() -> int:
    now = time.time()
    removed = 0
    for name, meta in list(st.session_state["uploads"].items()):
        if now - meta["uploaded_at"] >= TTL_SECONDS:
            st.session_state["uploads"].pop(name, None)
            removed += 1
    return removed

def _fmt_left(ts: float) -> str:
    left = max(0, TTL_SECONDS - int(time.time() - ts))
    m, s = divmod(left, 60)
    return f"{m:02d}:{s:02d}"

def _add_uploads(files: List) -> Tuple[List[str], List[str]]:
    added, replaced = [], []
    for f in files or []:
        name = Path(f.name).name.strip()
        data = f.read()
        existed = name in st.session_state["uploads"]
        st.session_state["uploads"][name] = {
            "data": data,
            "size": len(data),
            "uploaded_at": time.time(),
        }
        if existed:
            replaced.append(name)
        else:
            added.append(name)
    return added, replaced

def _clear_all():
    st.session_state["uploads"].clear()
    st.session_state["last_activity"] = time.time()

st.title("üßæ Invoice Pipeline ‚Äì Upload & Convert")

# auto refresh ƒë·ªÉ qu√©t TTL
autoref = getattr(st, "autorefresh", None) or getattr(st, "st_autorefresh", None)
if autoref:
    autoref(interval=AUTO_REFRESH_MS, key="auto_gc")

with st.expander("üîå K·∫øt n·ªëi Backend", expanded=True):
    backend_url_input = st.text_input(
        "Backend URL",
        value=_resolve_backend_url(),
        placeholder="https://<service>-<hash>-<region>.a.run.app",
    )
    c1, c2 = st.columns(2)
    with c1:
        if st.button("üíæ L∆∞u URL"):
            if backend_url_input.strip().startswith("http"):
                _write_backend_url(backend_url_input.strip())
                st.success("ƒê√£ l∆∞u URL backend.")
            else:
                st.error("Vui l√≤ng nh·∫≠p URL h·ª£p l·ªá.")
    with c2:
        if st.button("üîó Ki·ªÉm tra /health"):
            url = backend_url_input.strip()
            if not url:
                st.error("Ch∆∞a c√≥ Backend URL.")
            else:
                try:
                    r = requests.get(_join(url, "/health"), timeout=12)
                    st.info(f"Response: {r.status_code} ‚Äî {r.text[:500]}")
                except Exception as e:
                    st.error(f"Response: None ‚Äî {e!r}")
    if backend_url_input.strip():
        st.info("ƒêang d√πng: " + backend_url_input.strip())

_init_state()
removed = _cleanup_ttl()
if removed:
    st.info(f"üßπ ƒê√£ xo√° {removed} file h·∫øt h·∫°n (TTL {TTL_SECONDS//60} ph√∫t).")

st.subheader("Ch·ªçn nhi·ªÅu XML (d1‚Ä¶d5, ‚Ä¶)")
files = st.file_uploader("Drag and drop files here", type=["xml"], accept_multiple_files=True)
if files:
    added, replaced = _add_uploads(files)
    if added:
        st.success("‚úÖ Th√™m: " + ", ".join(added))
    if replaced:
        st.warning("‚ôªÔ∏è Ghi ƒë√®: " + ", ".join(replaced))
    st.session_state["last_activity"] = time.time()

if st.session_state["uploads"]:
    import pandas as pd
    df = pd.DataFrame([
        {"T√™n file": name,
         "K√≠ch th∆∞·ªõc (KB)": round(meta["size"]/1024, 1),
         "C√≤n l·∫°i (mm:ss)": _fmt_left(meta["uploaded_at"])}
        for name, meta in st.session_state["uploads"].items()
    ])
    st.caption("C√°c file ƒëang gi·ªØ t·∫°m (t·ª± xo√° sau 5 ph√∫t kh√¥ng t∆∞∆°ng t√°c):")
    st.dataframe(df, use_container_width=True, hide_index=True)
    if st.button("üßΩ Xo√° t·∫•t c·∫£ file (ngay)"):
        _clear_all()
        st.success("ƒê√£ xo√° t·∫•t c·∫£ file.")
        st.stop()
else:
    st.caption("Ch∆∞a c√≥ file n√†o.")
    - name: "gcr.io/cloud-builders/docker"
  args: ["push","\$_REGION-docker.pkg.dev/\$PROJECT_ID/\$_REPO/\$_SERVICE:\$SHORT_SHA"]

- name: "gcr.io/google.com/cloudsdktool/cloud-sdk"
  entrypoint: gcloud
  args:
    [
      "run","deploy","\$_SERVICE",
      "--image","\$_REGION-docker.pkg.dev/\$PROJECT_ID/\$_REPO/\$_SERVICE:\$SHORT_SHA",
      "--region","\$_REGION",
      "--allow-unauthenticated",
      "--platform","managed"
    ]

images:
- "\$_REGION-docker.pkg.dev/\$PROJECT_ID/\$_REPO/\$_SERVICE:\$SHORT_SHA"
EOF
  echo "‚úÖ Cloud Build: $CB"
fi

# ===== 5) Git add/commit/push main =====
cd "$ROOT_DIR"
git fetch origin || true
# x√°c ƒë·ªãnh nh√°nh ch√≠nh
MAIN="$(git remote show origin 2>/dev/null | awk "/HEAD branch/ {print \$NF}")"
[ -z "$MAIN" ] && MAIN="main"
git checkout "$MAIN" >/dev/null 2>&1 || true
git pull --rebase origin "$MAIN" || true
git add -A
git commit -m "feat(fe): update FE, TTL+replace, footer, CI deploy" || true
git push origin "$MAIN"

# ===== 6) Chu·∫©n b·ªã Artifact Registry repo (n·∫øu ch∆∞a c√≥) =====
if ! gcloud artifacts repositories describe "$REPO" --location="$REGION" >/dev/null 2>&1; then
  gcloud artifacts repositories create "$REPO" \
    --repository-format=docker \
    --location="$REGION" \
    --description="FE images for $SERVICE"
fi

# ===== 7) L·∫•y BACKEND_URL
merge_to_one = st.checkbox("G·ªôp nhi·ªÅu file th√†nh 1 Excel", value=True)

c3, _ = st.columns([1,4])
with c3:
    if st.button("üöÄ Convert"):
        backend = backend_url_input.strip() or _resolve_backend_url()
        if not backend:
            st.error("Ch∆∞a c·∫•u h√¨nh Backend URL."); st.stop()
        if not st.session_state["uploads"]:
            st.error("Vui l√≤ng ch·ªçn √≠t nh·∫•t 1 t·ªáp XML."); st.stop()

        try:
            form_files = [
                ("files", (name, io.BytesIO(meta["data"]), "application/xml"))
                for name, meta in st.session_state["uploads"].items()
            ]
            data = {"merge_to_one": "true" if merge_to_one else "false"}
            resp = requests.post(_join(backend, "/pipeline/xml-to-xlsx"),
                                 files=form_files, data=data, timeout=120)
        except Exception as e:
            st.error(f"Kh√¥ng g·ªçi ƒë∆∞·ª£c backend: {e}"); st.stop()

        if resp.status_code != 200:
            st.error(f"L·ªói t·ª´ backend ({resp.status_code}): {resp.text[:500]}"); st.stop()

        ctype = resp.headers.get("Content-Type", "application/octet-stream")
        cd = resp.headers.get("Content-Disposition", "")
        fname = "Data.xlsx"
        if "filename=" in cd:
            fname = cd.split("filename=")[-1].strip("\"'; ")
        st.success("‚úÖ Ho√†n t·∫•t. B·∫•m n√∫t ƒë·ªÉ t·∫£i xu·ªëng.")
        st.download_button("‚¨áÔ∏è Download", data=resp.content, file_name=fname, mime=ctype)
        _clear_all()

st.markdown("""
<div style="text-align:center;color:#6c757d;margin-top:32px;">
  ¬© 2025 Chuong Minh. All rights reserved. ¬∑
  <a href="https://m.me/michng99" target="_blank">Messenger</a>
</div>""", unsafe_allow_html=True)
PY
echo "‚úÖ FE file: $APP_DIR/streamlit_app.py"

# ===== 2) requirements.txt (n·∫øu thi·∫øu) =====
REQ="$APP_DIR/requirements.txt"
if [ ! -f "$REQ" ]; then
  cat > "$REQ" <<EOF
streamlit==1.39.0
requests
tomli
EOF
  echo "‚úÖ FE requirements: $REQ"
fi

# ===== 3) Dockerfile FE (n·∫øu thi·∫øu) =====
if [ ! -f "$APP_DIR/Dockerfile" ]; then
  cat > "$APP_DIR/Dockerfile" <<EOF
FROM python:3.12-slim
ENV PYTHONDONTWRITEBYTECODE=1
ENV PYTHONUNBUFFERED=1
WORKDIR /app
COPY requirements.txt /app/requirements.txt
RUN pip install --no-cache-dir -r /app/requirements.txt
COPY . /app
EXPOSE 8080
CMD ["streamlit","run","streamlit_app.py","--server.address=0.0.0.0","--server.port=8080","--server.enableCORS=false","--server.enableXsrfProtection=false","--browser.gatherUsageStats=false"]
EOF
  echo "‚úÖ FE Dockerfile: $APP_DIR/Dockerfile"
fi

# ===== 4) cloudbuild.yaml ·ªü th∆∞ m·ª•c g·ªëc =====
mkdir -p "$ROOT_DIR"
CB="$ROOT_DIR/cloudbuild.yaml"
if [ ! -f "$CB" ]; then
  cat > "$CB" <<EOF
substitutions:
  _REGION: "$REGION"
  _SERVICE: "$SERVICE"
  _REPO: "$REPO"

steps:
- name: "gcr.io/cloud-builders/docker"
  dir: "fe"
  args: ["build","-t","\$_REGION-docker.pkg.dev/\$PROJECT_ID/\$_REPO/\$_SERVICE:\$SHORT_SHA","."]